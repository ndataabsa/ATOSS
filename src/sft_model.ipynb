{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad35b396-940f-41df-a96c-d9f1953df111",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import pickle\n",
    "from functools import partial\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import seed_everything\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks.progress import TQDMProgressBar\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "\n",
    "\n",
    "from torch.optim import AdamW\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "from atoss.data_utils import *\n",
    "from atoss.eval_utils import *\n",
    "from atoss.process import *\n",
    "\n",
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fd5f990-f426-48ea-aa6b-8bdae8b7fcfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method: sft\n",
      "data path: /home/elicer/ATOSS/data/sft/acos/rest16\n",
      "output path: /home/elicer/ATOSS/outputs/sft/acos/rest16\n"
     ]
    }
   ],
   "source": [
    "# setting args\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.path = '/home/elicer/ATOSS'\n",
    "        self.method = 'sft' # task\n",
    "        self.model = 'final'\n",
    "        self.task = 'acos' # task\n",
    "        self.dataset = 'rest16' # task \n",
    "        self.train = 'train' # task \n",
    "        self.dev = 'dev' # task \n",
    "        self.eval_data_split = 'test' # test or dev\n",
    "        self.data_path = f'{self.path}/data/{self.method}/{self.task}/{self.dataset}'\n",
    "        self.ctrl_token = \"post\"\n",
    "        self.data_ratio = 1.0\n",
    "        self.model_name_or_path = 't5-base' # used base model\n",
    "        self.load_ckpt_name = 'epoch=9-val_f1=65.41-val_loss=0.14' # 사전 훈련된 모델의 체크포인트 파일로드 \n",
    "        self.do_train = False # train or not\n",
    "        self.do_inference = True # inference or not\n",
    "        self.max_seq_length = 512 # 입력 시퀀스 최대 길이\n",
    "        self.n_gpu = 1 # gpu 개수\n",
    "        self.train_batch_size = 16\n",
    "        self.eval_batch_size = 16\n",
    "        self.gradient_accumulation_steps = 1\n",
    "        self.learning_rate = 1e-5\n",
    "        self.num_train_epochs = 20\n",
    "        self.seed = 25\n",
    "        self.weight_decay = 0.0\n",
    "        self.adam_epsilon = 1e-8\n",
    "        self.warmup_steps = 0.0\n",
    "        self.multi_path = False\n",
    "        self.num_path = 1\n",
    "        self.beam_size = 1\n",
    "        self.save_top_k = 1\n",
    "        self.check_val_every_n_epoch = 10\n",
    "        self.sort_label = False\n",
    "        self.load_path_cache = False\n",
    "        self.lowercase = True\n",
    "        self.multi_task = False\n",
    "        self.constrained_decode = False\n",
    "\n",
    "def init_args():\n",
    "    args = Args()\n",
    "\n",
    "    args.output_dir =  f'{args.path}/outputs/{args.method}/{args.task}/{args.dataset}'\n",
    "\n",
    "    # set up output dir which looks like './outputs/rest15/'\n",
    "    if not os.path.exists(f'{args.path}/outputs'):\n",
    "        os.mkdir(f'{args.path}/outputs')\n",
    "\n",
    "    if not os.path.exists(args.output_dir):\n",
    "        #os.mkdir(args.output_dir)\n",
    "        os.makedirs(args.output_dir, exist_ok=True)\n",
    "\n",
    "    return args\n",
    "\n",
    "args = init_args()\n",
    "\n",
    "print('method:', args.method)\n",
    "print('data path:', args.data_path)\n",
    "print('output path:', args.output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3828147-5eb6-4b23-afe7-df3629081f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set as 25\n"
     ]
    }
   ],
   "source": [
    "set_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b426b4bb-2105-48ad-9482-899cb00afd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class T5FineTuner(pl.LightningModule):\n",
    "    \"\"\"\n",
    "    Fine tune a pre-trained T5 model\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config, tfm_model, tokenizer):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(ignore=['tfm_model'])\n",
    "        self.config = config\n",
    "        self.model = tfm_model\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def forward(self,\n",
    "                input_ids,\n",
    "                attention_mask=None,\n",
    "                decoder_input_ids=None,\n",
    "                decoder_attention_mask=None,\n",
    "                labels=None):\n",
    "        return self.model(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            decoder_input_ids=decoder_input_ids,\n",
    "            decoder_attention_mask=decoder_attention_mask,\n",
    "            labels=labels,\n",
    "        )\n",
    "\n",
    "    def _step(self, batch):\n",
    "        lm_labels = batch[\"target_ids\"]\n",
    "        lm_labels[lm_labels[:, :] == self.tokenizer.pad_token_id] = -100\n",
    "\n",
    "        outputs = self(input_ids=batch[\"source_ids\"],\n",
    "                       attention_mask=batch[\"source_mask\"],\n",
    "                       labels=lm_labels,\n",
    "                       decoder_attention_mask=batch['target_mask'])\n",
    "\n",
    "        loss = outputs[0]\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self._step(batch)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def evaluate(self, batch, stage=None):\n",
    "        # get f1\n",
    "        outs = self.model.generate(input_ids=batch['source_ids'],\n",
    "                                   attention_mask=batch['source_mask'],\n",
    "                                   max_length=self.config.max_seq_length,\n",
    "                                   return_dict_in_generate=True,\n",
    "                                   output_scores=True,\n",
    "                                   num_beams=1)\n",
    "\n",
    "        dec = [\n",
    "            self.tokenizer.decode(ids, skip_special_tokens=True)\n",
    "            for ids in outs.sequences\n",
    "        ]\n",
    "        target = [\n",
    "            self.tokenizer.decode(ids, skip_special_tokens=True)\n",
    "            for ids in batch[\"target_ids\"]\n",
    "        ]\n",
    "        scores, _, _ = compute_scores(dec, target, verbose=False)\n",
    "        f1 = torch.tensor(scores['f1'], dtype=torch.float64)\n",
    "\n",
    "        # get loss\n",
    "        loss = self._step(batch)\n",
    "\n",
    "        if stage:\n",
    "            self.log(f\"{stage}_loss\",\n",
    "                     loss,\n",
    "                     prog_bar=True,\n",
    "                     on_step=False,\n",
    "                     on_epoch=True)\n",
    "            self.log(f\"{stage}_f1\",\n",
    "                     f1,\n",
    "                     prog_bar=True,\n",
    "                     on_step=False,\n",
    "                     on_epoch=True)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        self.evaluate(batch, \"val\")\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        self.evaluate(batch, \"test\")\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\" Prepare optimizer and schedule (linear warmup and decay) \"\"\"\n",
    "        model = self.model\n",
    "        no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "        optimizer_grouped_parameters = [\n",
    "            {\n",
    "                \"params\": [\n",
    "                    p for n, p in model.named_parameters()\n",
    "                    if not any(nd in n for nd in no_decay)\n",
    "                ],\n",
    "                \"weight_decay\":\n",
    "                self.config.weight_decay,\n",
    "            },\n",
    "            {\n",
    "                \"params\": [\n",
    "                    p for n, p in model.named_parameters()\n",
    "                    if any(nd in n for nd in no_decay)\n",
    "                ],\n",
    "                \"weight_decay\":\n",
    "                0.0,\n",
    "            },\n",
    "        ]\n",
    "        optimizer = AdamW(optimizer_grouped_parameters,\n",
    "                          lr=self.config.learning_rate,\n",
    "                          eps=self.config.adam_epsilon)\n",
    "        scheduler = {\n",
    "            \"scheduler\":\n",
    "            get_linear_schedule_with_warmup(optimizer,\n",
    "                                            **self.config.lr_scheduler_init),\n",
    "            \"interval\":\n",
    "            \"step\",\n",
    "        }\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        print(\"load training data.\")\n",
    "        train_dataset = ABSADataset(args=args,\n",
    "                                    tokenizer=tokenizer,\n",
    "                                    task_name=args.task,\n",
    "                                    data_type=args.train,\n",
    "                                    max_len=args.max_seq_length)\n",
    "        dataloader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=self.config.train_batch_size,\n",
    "            drop_last=True\n",
    "            if args.data_ratio > 0.3 else False, # don't drop on few-shot\n",
    "            shuffle=True,\n",
    "            num_workers=2)\n",
    "\n",
    "        return dataloader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        val_dataset = ABSADataset(args=args,\n",
    "                                    tokenizer=tokenizer,\n",
    "                                    task_name=args.task,\n",
    "                                    data_type=args.dev,\n",
    "                                    max_len=args.max_seq_length)\n",
    "        return DataLoader(val_dataset,\n",
    "                          batch_size=self.config.eval_batch_size,\n",
    "                          num_workers=2)\n",
    "\n",
    "    @staticmethod\n",
    "    def rindex(_list, _value):\n",
    "        return len(_list) - _list[::-1].index(_value) - 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29eb89dc-cf16-4c73-b22d-60ed6648a11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do train\n",
    "if args.do_train:\n",
    "\n",
    "    # mvp sample 수 확인  \n",
    "    print(\"\\n\", \"=\" * 30, f\"NEW EXP: Task : {args.task}\",\"=\" * 30, \"\\n\")\n",
    "    tokenizer = T5Tokenizer.from_pretrained(args.model_name_or_path)\n",
    "    # sanity check\n",
    "    # show one sample to check the code and the expected output\n",
    "    print(f\"Here is an example (from the dev set):\")\n",
    "    dataset = ABSADataset(tokenizer=tokenizer,\n",
    "                      task_name=args.task,\n",
    "                      data_type=args.train,\n",
    "                      args=args,\n",
    "                      max_len=args.max_seq_length)\n",
    "\n",
    "    # initialize the T5 model\n",
    "    tfm_model = T5ForConditionalGeneration.from_pretrained(args.model_name_or_path)\n",
    "    model = T5FineTuner(args, tfm_model, tokenizer)\n",
    "    \n",
    "    # load data\n",
    "    train_loader = model.train_dataloader()\n",
    "    \n",
    "    # config optimizer\n",
    "    t_total = ((len(train_loader.dataset) //\n",
    "                (args.train_batch_size * max(1, args.n_gpu))) //\n",
    "               args.gradient_accumulation_steps *\n",
    "               float(args.num_train_epochs))\n",
    "    \n",
    "    args.lr_scheduler_init = {\n",
    "        \"num_warmup_steps\": args.warmup_steps,\n",
    "        \"num_training_steps\": t_total\n",
    "    }\n",
    "    \n",
    "    checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "        dirpath=args.output_dir,\n",
    "        filename='{epoch}-{val_f1:.2f}-{val_loss:.2f}',\n",
    "        monitor='val_f1',\n",
    "        mode='max',\n",
    "        save_top_k=args.save_top_k,\n",
    "        save_last=False)\n",
    "    \n",
    "    early_stop_callback = EarlyStopping(monitor=\"val_f1\",\n",
    "                                        min_delta=0.00,\n",
    "                                        patience=20,\n",
    "                                        verbose=True,\n",
    "                                        mode=\"max\")\n",
    "    lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "    \n",
    "    # prepare for trainer\n",
    "    train_params = dict(\n",
    "        accelerator=\"gpu\",\n",
    "        devices=1,\n",
    "        default_root_dir=args.output_dir,\n",
    "        accumulate_grad_batches=args.gradient_accumulation_steps,\n",
    "        gradient_clip_val=1.0,\n",
    "        max_epochs=args.num_train_epochs,\n",
    "        check_val_every_n_epoch=args.check_val_every_n_epoch,\n",
    "        callbacks=[\n",
    "            checkpoint_callback, early_stop_callback,\n",
    "            TQDMProgressBar(refresh_rate=10), lr_monitor\n",
    "        ],\n",
    "    )\n",
    "    \n",
    "    trainer = pl.Trainer(**train_params)\n",
    "    \n",
    "    trainer.fit(model)\n",
    "    \n",
    "    # save the final model\n",
    "    model.model.save_pretrained(os.path.join(args.output_dir, args.model))\n",
    "    tokenizer.save_pretrained(os.path.join(args.output_dir, args.model))\n",
    "    print(\"Finish training and saving the model!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77c79dc6-6fde-4bad-92f1-38a5123b3e03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/elicer/ATOSS/outputs/sft/acos/rest16/final\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****** Conduct inference on trained checkpoint ******\n",
      "Loading ckpt: /home/elicer/ATOSS/outputs/sft/acos/rest16/epoch=9-val_f1=65.41-val_loss=0.14.ckpt\n",
      " model: final, beam: 1, constrained: False\n",
      "\n",
      "Total examples = 583\n",
      "Total examples = 583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37/37 [00:56<00:00,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred labels count Counter({1: 583})\n",
      "gold  yum!\n",
      "pred  yum!\n",
      "\n",
      "gold  serves really good sushi.\n",
      "pred  serves really good sushi.\n",
      "\n",
      "gold  not the biggest portions but adequate.\n",
      "pred  not the biggest portions but adequate.\n",
      "\n",
      "gold  green tea creme brulee is a must!\n",
      "pred  green tea creme brulee is a must!\n",
      "\n",
      "gold  it has great sushi and even better service.\n",
      "pred  it has great sushi. it has even better service.\n",
      "\n",
      "gold  the entire staff was extremely accomodating and tended to my every need.\n",
      "pred  the entire staff was extremely accomodating. they tended to my every need.\n",
      "\n",
      "gold  i've been to this restaurant over a dozen times with no complaints to date.\n",
      "pred  i've been to this restaurant over a dozen times with no complaints to date.\n",
      "\n",
      "gold  the owner is belligerent to guests that have a complaint.\n",
      "pred  the owner is belligerent to guests that have a complaint.\n",
      "\n",
      "gold  good food!\n",
      "pred  good food!\n",
      "\n",
      "gold  this is a great place to get a delicious meal.\n",
      "pred  this is a great place to get a delicious meal.\n",
      "\n",
      "number of gold spans: 583, predicted spans: 583, hit: 341\n",
      "model: final data: test precision: 58.49 recall: 58.49 F1 = 58.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# do inference\n",
    "if args.do_inference:\n",
    "    # load the outdir\n",
    "    model_path = os.path.join(args.output_dir, args.model)\n",
    "    print(model_path)\n",
    "    tfm_model = T5ForConditionalGeneration.from_pretrained(model_path)\n",
    "    tokenizer = T5Tokenizer.from_pretrained(model_path)\n",
    "    model = T5FineTuner(args, tfm_model, tokenizer)\n",
    "   \n",
    "    print(\"\\n****** Conduct inference on trained checkpoint ******\")\n",
    "    \n",
    "    if args.load_ckpt_name:\n",
    "        ckpt_path = os.path.join(args.output_dir, f'{args.load_ckpt_name}.ckpt')\n",
    "        print(\"Loading ckpt:\", ckpt_path)\n",
    "        checkpoint = torch.load(ckpt_path)\n",
    "        model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    \n",
    "    log_file_path = os.path.join(args.output_dir, \"result.txt\")\n",
    "    \n",
    "    \n",
    "    # compute the performance scores\n",
    "    with open(log_file_path, \"a+\") as f:\n",
    "        config_str = f\" model: {args.model}, beam: {args.beam_size}, constrained: {args.constrained_decode}\\n\"\n",
    "        print(config_str)\n",
    "        f.write(config_str)\n",
    "        scores = evaluate(args,\n",
    "                          model,\n",
    "                          args.task,\n",
    "                          data_type=args.eval_data_split)\n",
    "    \n",
    "        exp_results = \"model: {} data: {} precision: {:.2f} recall: {:.2f} F1 = {:.2f}\".format(\n",
    "            args.model, args.eval_data_split, scores['precision'], scores['recall'], scores['f1'])\n",
    "        print(exp_results)\n",
    "        f.write(exp_results + \"\\n\")\n",
    "        f.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e91eccb-5380-4278-b789-838182f3b795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yum!'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = os.path.join(\n",
    "        args.output_dir, \"result_{}_{}_{}_{}{}beam{}.pickle\".format(\n",
    "            args.method,\n",
    "            args.model,\n",
    "            args.eval_data_split,\n",
    "            \"best_\" if args.load_ckpt_name else \"\",\n",
    "            \"cd_\" if args.constrained_decode else \"\",\n",
    "            args.beam_size))\n",
    "with open(file_path, 'rb') as f:\n",
    "    loaded_object = pd.read_pickle(f)\n",
    "loaded_object[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89779428-0bf3-4692-9107-db9cf62c6be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read. Total count:  583\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"[['NULL', 'food quality', 'positive', 'yum']]\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = f'/home/elicer/ABSA/data/{args.task}/{args.dataset}/test.txt'\n",
    "_, targets = split_sharp(file)\n",
    "targets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90ca3a79-ea32-4985-be13-12841209a9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read. Total count:  583\n",
      "Input count: 583\n",
      "Expanded target count: 583\n",
      "Merged data count: 583\n",
      "Data return. Total count: 583\n",
      "/home/elicer/ABSA/data/acos/rest16/result_sft_final_test_best_beam1.txt\n"
     ]
    }
   ],
   "source": [
    "file = f'/home/elicer/ABSA/data/{args.task}/{args.dataset}/test.txt'\n",
    "_, targets = split_sharp(file)\n",
    "sft = merge_sharp_n(loaded_object[0],targets)\n",
    "file_name = os.path.join(f'/home/elicer/ABSA/data/{args.task}/{args.dataset}',\n",
    "                         \"result_{}_{}_{}_{}{}beam{}.txt\".format(\n",
    "                             args.method,\n",
    "                             args.model,\n",
    "                             args.eval_data_split,\n",
    "                              \"best_\" if args.load_ckpt_name else \"\",\n",
    "                             \"cd_\" if args.constrained_decode else \"\",\n",
    "                              args.beam_size))\n",
    "print(file_name)\n",
    "with open(file_name, 'w', encoding='UTF-8') as file:\n",
    "    for line in sft:\n",
    "        file.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616e3619-3ae6-4bca-b89d-591bf9314985",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb1c48a-c18b-4407-9c23-2a86d10469f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atoss",
   "language": "python",
   "name": "atoss"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
